# TransRapport MVP - Live-Transkription fÃ¼r Therapeuten

Eine Desktop-Anwendung fÃ¼r Live-Transkription mit therapeutischen Markern, entwickelt speziell fÃ¼r therapeutische Anwendungen mit Fokus auf Datenschutz und Offline-Betrieb.

## Features

### ğŸ¤ Live-Transkription
- **Offline-Betrieb** mit Whisper (faster-whisper)
- **Echtzeit-Transkription** wÃ¤hrend der Sitzung
- **Mehrsprachig**: Deutsch, Englisch, Auto-Erkennung
- **Verschiedene ModellgrÃ¶ÃŸen**: tiny, base, small, medium

### ğŸ§  Therapeutische Marker-Analyse (ATOâ†’SEM)
- **Affect (Emotionen)**: Automatische Emotionserkennung aus Sprache
- **Tempo**: Pausen-Erkennung und Sprechgeschwindigkeit
- **Other Prosody**: TonhÃ¶he und Energie-Analyse
- **Live-Visualisierung** aller Marker wÃ¤hrend der Sitzung

### ğŸ’¾ Session-Management
- **Sitzungen speichern und laden**
- **VollstÃ¤ndige Marker-Daten** werden mitgespeichert
- **Session-Ãœbersicht** mit Details und Statistiken

### ğŸ“„ Export-FunktionalitÃ¤t
- **Text-Export** (.txt) mit Marker-Zusammenfassung
- **Markdown-Export** (.md) mit strukturierten Tabellen
- **Therapeutische Hinweise** basierend auf Marker-Analyse

### ğŸ¨ Therapeutenfreundliche GUI
- **Minimalistische OberflÃ¤che** fÃ¼r professionelle Nutzung
- **Live-Marker-Visualisierung** mit Plots und Statistiken
- **Audio-Pegel-Anzeige** fÃ¼r optimale Aufnahme
- **Intuitive Bedienung** mit TastaturkÃ¼rzeln

## Systemanforderungen

- **Python 3.8+**
- **FFmpeg** (fÃ¼r Audio-Verarbeitung)
- **Mikrofon** fÃ¼r Live-Aufnahme
- **4GB RAM** (empfohlen fÃ¼r base-Modell)
- **2GB freier Speicherplatz** (fÃ¼r Whisper-Modelle)

## Installation

### Schnellstart (Linux/Windows)

#### 1. Repository klonen oder herunterladen
```bash
git clone <repository-url>
cd transrapport_mvp
```

#### 2. Python Virtual Environment erstellen
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/macOS
source venv/bin/activate
```

#### 3. AbhÃ¤ngigkeiten installieren
```bash
pip install -r requirements.txt
```

#### 4. FFmpeg installieren

**Windows:**
- FFmpeg von https://ffmpeg.org/download.html herunterladen
- Zu PATH hinzufÃ¼gen

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install ffmpeg
```

#### 5. Anwendung starten
```bash
python main.py
```

### ğŸ macOS-spezifische Installation

**macOS-Nutzer haben oft Probleme mit HDF5-AbhÃ¤ngigkeiten (PyTables) und PyQt-Installation.**

**â†’ Verwenden Sie die detaillierte [macOS-Installationsanleitung](docs/INSTALL_MACOS.md)**

Die macOS-Anleitung lÃ¶st bekannte Probleme wie:
- `'H5public.h' file not found` Fehler
- PyTables Installation schlÃ¤gt fehl
- PyQt6/pyqtgraph Wheel-Probleme
- Apple Silicon (M1/M2) KompatibilitÃ¤t

**Kurz-Version fÃ¼r macOS:**
```bash
# HDF5 Ã¼ber Homebrew installieren
brew install hdf5 python ffmpeg

# HDF5-Pfad setzen
export HDF5_DIR=$(brew --prefix hdf5)

# macOS-spezifische requirements verwenden
pip install -r requirements_macos.txt
HDF5_DIR=$HDF5_DIR pip install tables
```

## Erste Schritte

### 1. Mikrofon einrichten
- Mikrofon anschlieÃŸen und in den Einstellungen auswÃ¤hlen
- "Aktualisieren" klicken, um verfÃ¼gbare GerÃ¤te zu laden
- Audio-Pegel prÃ¼fen (grÃ¼ner Balken sollte bei Sprache ausschlagen)

### 2. Sprache und Modell wÃ¤hlen
- **Sprache**: Deutsch (empfohlen fÃ¼r deutsche Sitzungen)
- **Modell**: base (guter Kompromiss zwischen Geschwindigkeit und QualitÃ¤t)

### 3. Live-Transkription starten
- "Live-Transkription starten" klicken
- Sprechen - Text erscheint in Echtzeit
- Marker werden automatisch analysiert und visualisiert

### 4. Sitzung verwalten
- **Neue Sitzung**: Strg+N
- **Sitzung speichern**: Strg+S
- **Sitzung laden**: Strg+O

### 5. Export
- **Datei â†’ Exportieren â†’ Als Text (.txt)**: Einfacher Textexport
- **Datei â†’ Exportieren â†’ Als Markdown (.md)**: Strukturierter Export mit Tabellen

## Therapeutische Marker

### Affect (Emotionen)
- **Erkannte Emotionen**: happy, sad, angry, excited, calm, anxious, neutral
- **Valenz-Werte**: -1 (negativ) bis +1 (positiv)
- **Confidence-Score**: ZuverlÃ¤ssigkeit der Erkennung

### Tempo (Pausen)
- **Pause-Erkennung**: Automatisch ab 600ms Stille
- **Sprechgeschwindigkeit**: WÃ¶rter pro Minute
- **Pause-Statistiken**: Durchschnitt, Maximum, Anzahl

### Prosody (Stimmmerkmale)
- **TonhÃ¶he (Pitch)**: Grundfrequenz in Hz
- **Energie (RMS)**: LautstÃ¤rke und IntensitÃ¤t
- **StabilitÃ¤t**: VariabilitÃ¤t der Stimmmerkmale

## Datenschutz und Sicherheit

- âœ… **VollstÃ¤ndig offline** - keine Internetverbindung erforderlich
- âœ… **Lokale Speicherung** - alle Daten bleiben auf Ihrem Computer
- âœ… **Keine Cloud-Services** - keine Ãœbertragung an externe Server
- âœ… **DSGVO-konform** - entwickelt fÃ¼r therapeutische Anwendungen

## Ordnerstruktur

```
transrapport_mvp/
â”œâ”€â”€ main.py                 # Hauptanwendung
â”œâ”€â”€ gui.py                  # BenutzeroberflÃ¤che
â”œâ”€â”€ live_transcriber.py     # Live-Transkription
â”œâ”€â”€ marker_system.py        # Therapeutische Marker
â”œâ”€â”€ exporter.py            # Export-FunktionalitÃ¤t
â”œâ”€â”€ session_manager.py     # Session-Management
â”œâ”€â”€ audio.py               # Audio-Verarbeitung
â”œâ”€â”€ config.ini             # Konfiguration
â”œâ”€â”€ requirements.txt       # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ sessions/              # Gespeicherte Sitzungen
â”œâ”€â”€ exports/               # Exportierte Dateien
â”œâ”€â”€ transcripts/           # Alte Transkripte (Legacy)
â””â”€â”€ models/                # Whisper-Modelle (automatisch)
```

## TastaturkÃ¼rzel

- **Strg+N**: Neue Sitzung
- **Strg+O**: Sitzung laden
- **Strg+S**: Sitzung speichern
- **Strg+Q**: Anwendung beenden

## Fehlerbehebung

### Whisper-Modell wird nicht geladen
- Internetverbindung beim ersten Start erforderlich
- Modell wird automatisch heruntergeladen (ca. 74MB fÃ¼r base)
- Bei Problemen: `models/` Ordner lÃ¶schen und neu starten

### Kein Mikrofon erkannt
- Mikrofon anschlieÃŸen und "Aktualisieren" klicken
- Systemeinstellungen prÃ¼fen (Mikrofon-Berechtigung)
- Andere Anwendungen schlieÃŸen, die das Mikrofon verwenden

### Schlechte TranskriptionsqualitÃ¤t
- GrÃ¶ÃŸeres Modell wÃ¤hlen (small oder medium)
- NÃ¤her zum Mikrofon sprechen
- HintergrundgerÃ¤usche reduzieren
- Korrekte Sprache auswÃ¤hlen

### Performance-Probleme
- Kleineres Modell wÃ¤hlen (tiny)
- Andere Anwendungen schlieÃŸen
- Mehr RAM verfÃ¼gbar machen

## Technische Details

### Verwendete Technologien
- **faster-whisper**: Optimierte Whisper-Implementation
- **PyQt6**: Moderne GUI-Framework
- **librosa**: Audio-Analyse und Feature-Extraktion
- **webrtcvad**: Voice Activity Detection
- **pyqtgraph**: Echtzeit-Plots und Visualisierung
- **numpy**: Numerische Berechnungen

### Marker-Algorithmen
- **Emotionserkennung**: Spektrale Features + Regelbasierte Klassifikation
- **Pausen-Erkennung**: WebRTC VAD mit konfigurierbaren Schwellenwerten
- **Prosody-Analyse**: Pitch-Tracking und RMS-Energie mit librosa

## Support und Entwicklung

### Bekannte Limitationen
- Emotionserkennung ist vereinfacht (fÃ¼r MVP)
- Nur Mono-Audio unterstÃ¼tzt
- Deutsche und englische Sprache optimiert

### Geplante Features
- Erweiterte Emotionsmodelle
- ZusÃ¤tzliche Sprachen
- Cloud-Synchronisation (optional)
- Erweiterte Statistiken

## Lizenz

Entwickelt fÃ¼r therapeutische Anwendungen. Alle Rechte vorbehalten.

---

**Version**: 1.0  
**Entwickelt**: 2025  
**FÃ¼r**: Therapeutische Praxis mit Fokus auf Datenschutz
