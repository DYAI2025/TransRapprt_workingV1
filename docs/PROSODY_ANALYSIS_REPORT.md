# Prosody-Gewichtung und Scoring-Mechanismen Analyse
## TransRapport vs. TRAPV4-inspirierte Verbesserungen

*Datum: 11. September 2025*  
*Analyst: Claude Code Quality Analyzer*

---

## Executive Summary

Diese Analyse untersucht die aktuellen Prosodie-Gewichtungs- und Scoring-Mechanismen im TransRapport-System und vergleicht sie mit modernen Prosody-Analyse-Techniken, die in der Forschung zu Frame-basierter RMS- und F0-Extraktion, Z-Score-Normalisierung und Moving-Average-Techniken verwendet werden.

**Haupterkenntnisse:**
- Das aktuelle System verwendet grundlegende Prosody-Features ohne statistische Normalisierung
- Fehlende adaptive Kalibrierung und Gewichtungsmechanismen
- Verbesserungspotenzial f√ºr pr√§zisere Emotionserkennung durch erweiterte Feature-Engineering
- M√∂glichkeit zur Implementierung von Loudness Spike Detection und erweiterten Pause-Klassifikationen

---

## 1. Aktuelle Implementierung - Analyse des marker_system.py

### 1.1 Frame-basierte Feature-Extraktion

**Aktuelle Implementierung:**
```python
# RMS-Extraktion (Zeile 176, 361)
rms = np.sqrt(np.mean(audio_segment**2))
rms_frames = librosa.feature.rms(y=audio_segment, frame_length=512, hop_length=256)[0]

# F0-Extraktion (Zeile 343-350)
pitches, magnitudes = librosa.piptrack(
    y=audio_segment, 
    sr=self.sample_rate,
    threshold=0.1,
    fmin=80,   # Minimum F0 f√ºr Sprache
    fmax=400   # Maximum F0 f√ºr Sprache
)
```

**Bewertung:**
- ‚úÖ Grundlegende RMS- und F0-Extraktion implementiert
- ‚ùå Keine Frame-basierte Kontinuit√§t oder Trend-Analyse
- ‚ùå Fehlende statistische Normalisierung
- ‚ùå Keine adaptive Fenstergr√∂√üen-Anpassung

### 1.2 Emotionsklassifikation

**Aktuelle Implementierung:**
```python
def _classify_emotion_simple(self, rms: float, zcr: float, 
                           spectral_centroid: float, spectral_rolloff: float):
    # Normalisierte Features (Zeile 219-222)
    energy_level = min(rms * 100, 1.0)  # 0-1
    activity_level = min(zcr * 10, 1.0)  # 0-1
    brightness = min(spectral_centroid / 4000, 1.0)  # 0-1
    
    # Therapeutisch relevante Emotionskategorien - KALIBRIERT (Zeile 224-251)
    if energy_level > 0.85 and activity_level > 0.8:
        # Regeln-basierte Klassifikation...
```

**Bewertung:**
- ‚úÖ Therapeutisch relevante Emotionskategorien (7 Klassen)
- ‚úÖ Grundlegende Feature-Normalisierung
- ‚ùå Statische Schwellenwerte ohne adaptive Kalibrierung
- ‚ùå Fehlende Machine Learning-basierte Klassifikation
- ‚ùå Keine statistischen Konfidenzma√üe

### 1.3 Pause-Erkennung und Timing

**Aktuelle Implementierung:**
```python
def _analyze_pauses(self, audio_data: np.ndarray, timestamp: datetime):
    # WebRTC VAD mit 30ms Frames (Zeile 292-293)
    frame_duration = 30  # ms
    frame_size = int(self.sample_rate * frame_duration / 1000)
    
    # Minimum Pause-Dauer (Zeile 48)
    self.min_pause_duration = 0.6  # 600ms f√ºr therapeutisch relevante Pause
```

**Bewertung:**
- ‚úÖ WebRTC VAD f√ºr robuste Spracherkennung
- ‚úÖ Therapeutisch relevante Pause-Schwellenwerte
- ‚ùå Keine Pause-Klassifikation (kurz/mittel/lang)
- ‚ùå Fehlende Kontext-abh√§ngige Pause-Bewertung

---

## 2. TRAPV4-inspirierte Verbesserungsvorschl√§ge

Basierend auf der Recherche zu modernen Prosody-Analyse-Techniken werden folgende Verbesserungen empfohlen:

### 2.1 Erweiterte Frame-basierte RMS und F0-Extraktion

**Empfohlene Verbesserungen:**

```python
class AdvancedProsodyAnalyzer:
    def __init__(self):
        self.frame_size = 25  # ms (40 Hz analysis rate)
        self.hop_length = 10  # ms (overlap f√ºr Stabilit√§t)
        self.z_score_window = 50  # Frames f√ºr lokale Normalisierung
        
    def extract_enhanced_features(self, audio_segment):
        """
        TRAPV4-inspirierte Feature-Extraktion mit:
        - Kontinuierlicher F0-Tracking
        - Lokale Z-Score-Normalisierung
        - Moving Average Gl√§ttung
        """
        # 1. Frame-basierte kontinuierliche Extraktion
        features = self._extract_frame_features(audio_segment)
        
        # 2. Z-Score Normalisierung (lokales Fenster)
        normalized_features = self._z_score_normalize(features)
        
        # 3. Moving Average Gl√§ttung f√ºr Trend-Analyse
        smoothed_features = self._moving_average_smooth(normalized_features)
        
        # 4. Derivative Features (Delta, Delta-Delta)
        delta_features = self._compute_derivatives(smoothed_features)
        
        return {
            'f0_trajectory': smoothed_features['f0'],
            'rms_trajectory': smoothed_features['rms'],
            'f0_delta': delta_features['f0_delta'],
            'rms_delta': delta_features['rms_delta'],
            'stability_metrics': self._compute_stability(smoothed_features)
        }
```

### 2.2 Z-Score Normalisierung und Moving Average

**Implementierungsvorschlag:**

```python
def _z_score_normalize(self, features, window_size=50):
    """
    Lokale Z-Score-Normalisierung f√ºr adaptive Kalibrierung
    """
    normalized = {}
    for feature_name, values in features.items():
        # Sliding window normalization
        normalized_values = []
        for i in range(len(values)):
            start_idx = max(0, i - window_size // 2)
            end_idx = min(len(values), i + window_size // 2)
            window_data = values[start_idx:end_idx]
            
            if len(window_data) > 1:
                mean = np.mean(window_data)
                std = np.std(window_data)
                if std > 0:
                    norm_val = (values[i] - mean) / std
                else:
                    norm_val = 0.0
            else:
                norm_val = 0.0
            
            normalized_values.append(norm_val)
        
        normalized[feature_name] = np.array(normalized_values)
    
    return normalized

def _moving_average_smooth(self, features, window_size=5):
    """
    Moving Average Gl√§ttung f√ºr Rauschreduktion
    """
    smoothed = {}
    for feature_name, values in features.items():
        # Exponential moving average f√ºr bessere Reaktivit√§t
        alpha = 2.0 / (window_size + 1)
        smoothed_values = [values[0]]  # Initialisierung
        
        for i in range(1, len(values)):
            smoothed_val = alpha * values[i] + (1 - alpha) * smoothed_values[-1]
            smoothed_values.append(smoothed_val)
        
        smoothed[feature_name] = np.array(smoothed_values)
    
    return smoothed
```

### 2.3 Loudness Spike Detection

**Neue Implementierung:**

```python
def detect_loudness_spikes(self, rms_trajectory, threshold_factor=2.5):
    """
    Erkennung von Lautst√§rke-Spitzen f√ºr emotionale Marker
    """
    # Lokale Statistiken f√ºr adaptive Schwellenwerte
    local_mean = self._moving_average_smooth({'rms': rms_trajectory})['rms']
    local_std = self._compute_moving_std(rms_trajectory)
    
    # Spike-Detektion
    spikes = []
    for i, (rms_val, mean_val, std_val) in enumerate(zip(rms_trajectory, local_mean, local_std)):
        if std_val > 0:
            z_score = (rms_val - mean_val) / std_val
            if z_score > threshold_factor:
                spikes.append({
                    'frame': i,
                    'intensity': z_score,
                    'emotional_relevance': self._classify_spike_emotion(z_score)
                })
    
    return spikes

def _classify_spike_emotion(self, intensity):
    """
    Emotional relevance of loudness spikes
    """
    if intensity > 4.0:
        return 'high_arousal'  # Sehr starke emotionale Reaktion
    elif intensity > 3.0:
        return 'moderate_arousal'  # Mittlere emotionale Reaktion
    else:
        return 'low_arousal'  # Schwache emotionale Reaktion
```

### 2.4 Erweiterte Pause-Klassifikation

**Verbesserter Ansatz:**

```python
def classify_pauses_advanced(self, pause_durations, speech_context):
    """
    Erweiterte Pause-Klassifikation mit Kontext-Awareness
    """
    classifications = []
    
    for duration in pause_durations:
        # Basis-Klassifikation
        if duration < 0.2:
            base_class = 'micro_pause'
        elif duration < 0.6:
            base_class = 'short_pause'
        elif duration < 1.5:
            base_class = 'medium_pause'
        else:
            base_class = 'long_pause'
        
        # Kontext-abh√§ngige Bewertung
        therapeutic_relevance = self._assess_therapeutic_relevance(
            duration, base_class, speech_context
        )
        
        classifications.append({
            'duration': duration,
            'type': base_class,
            'therapeutic_score': therapeutic_relevance,
            'emotional_indicator': self._pause_emotion_indicator(duration)
        })
    
    return classifications

def _assess_therapeutic_relevance(self, duration, pause_type, context):
    """
    Therapeutische Relevanz von Pausen bewerten
    """
    # Scoring basierend auf therapeutischen Erkenntnissen
    base_scores = {
        'micro_pause': 0.2,    # Normale Sprechpausen
        'short_pause': 0.6,    # Leichte Unsicherheit/Nachdenkpausen
        'medium_pause': 0.9,   # Bedeutende √úberlegungspausen
        'long_pause': 1.0      # Starke emotionale/kognitive Belastung
    }
    
    base_score = base_scores.get(pause_type, 0.5)
    
    # Kontext-Modifikatoren
    if context.get('preceding_emotion') in ['anxious', 'sad']:
        base_score *= 1.3  # H√∂here Relevanz bei emotionaler Belastung
    
    if context.get('speech_rate') < 120:  # Langsame Sprache
        base_score *= 1.2  # Verst√§rkung bei bereits langsamem Sprechen
    
    return min(base_score, 1.0)
```

---

## 3. Scoring-Gewichte und Kalibrierung

### 3.1 Aktuelle Gewichtung

**Problem-Analyse:**
```python
# Aktuelle Confidence-Berechnung (Zeile 250)
confidence = min((energy_level + activity_level + brightness) / 3 * 1.5, 1.0)
```

**Probleme:**
- Gleichgewichtung aller Features
- Statischer Multiplikator (1.5)
- Keine Feature-spezifische Gewichtung

### 3.2 Empfohlene adaptive Gewichtung

```python
class AdaptiveScoringSystem:
    def __init__(self):
        # Therapeutisch kalibrierte Gewichte
        self.feature_weights = {
            'f0_stability': 0.25,      # Pitch-Konsistenz
            'energy_dynamics': 0.20,   # RMS-Variationen
            'spectral_balance': 0.15,  # Spektrale Features
            'temporal_patterns': 0.15, # Timing und Pausen
            'voice_quality': 0.15,     # Stimmqualit√§t
            'emotional_markers': 0.10  # Emotional relevante Spitzen
        }
        
        # Adaptive Kalibrierung basierend auf Speaker
        self.speaker_normalization = True
        self.confidence_threshold = 0.7
    
    def compute_weighted_score(self, features):
        """
        Gewichtete Scoring mit therapeutischer Relevanz
        """
        weighted_score = 0.0
        confidence_factors = []
        
        for feature_name, weight in self.feature_weights.items():
            if feature_name in features:
                feature_value = features[feature_name]
                feature_confidence = self._compute_feature_confidence(
                    feature_name, feature_value
                )
                
                weighted_score += weight * feature_value * feature_confidence
                confidence_factors.append(feature_confidence)
        
        overall_confidence = np.mean(confidence_factors) if confidence_factors else 0.0
        
        return {
            'score': weighted_score,
            'confidence': overall_confidence,
            'reliable': overall_confidence >= self.confidence_threshold
        }
    
    def _compute_feature_confidence(self, feature_name, feature_value):
        """
        Feature-spezifische Konfidenz basierend auf Stabilit√§t
        """
        if feature_name == 'f0_stability':
            # H√∂here Konfidenz bei stabiler Pitch
            return 1.0 - min(feature_value, 1.0)
        elif feature_name == 'energy_dynamics':
            # Optimal bei mittlerer Dynamik
            return 1.0 - abs(feature_value - 0.5) * 2
        else:
            # Standard-Konfidenz
            return 0.8
```

---

## 4. Therapeutische Marker-Relevanz

### 4.1 Aktuelle therapeutische Kategorien

**Bewertung der aktuellen Emotionen:**
- ‚úÖ happy, sad, angry, excited, calm, anxious, neutral
- ‚úÖ Valence-Bewertung (-1 bis +1)
- ‚ùå Fehlende Intensit√§ts-Graduierung
- ‚ùå Keine zeitliche Kontinuit√§t-Analyse

### 4.2 Erweiterte therapeutische Marker

```python
class TherapeuticMarkerSystem:
    def __init__(self):
        self.therapeutic_dimensions = {
            'arousal': {  # Aktivierung/Erregung
                'low': ['calm', 'relaxed', 'tired'],
                'medium': ['neutral', 'focused'],
                'high': ['excited', 'anxious', 'angry']
            },
            'valence': {  # Emotionale Wertigkeit
                'negative': ['sad', 'angry', 'anxious'],
                'neutral': ['neutral', 'calm'],
                'positive': ['happy', 'excited', 'relaxed']
            },
            'cognitive_load': {  # Kognitive Belastung
                'low': ['calm', 'relaxed'],
                'medium': ['neutral', 'focused'],
                'high': ['stressed', 'overwhelmed']
            }
        }
    
    def assess_therapeutic_relevance(self, emotion_sequence, prosody_features):
        """
        Therapeutische Relevanz-Bewertung
        """
        # 1. Emotionale Stabilit√§t √ºber Zeit
        stability = self._compute_emotional_stability(emotion_sequence)
        
        # 2. Arousal-Valence Mapping
        arousal_valence = self._map_arousal_valence(emotion_sequence)
        
        # 3. Prosodische Konsistenz
        prosody_consistency = self._assess_prosody_consistency(prosody_features)
        
        # 4. Therapeutische Interventions-Empfehlungen
        interventions = self._suggest_interventions(
            stability, arousal_valence, prosody_consistency
        )
        
        return {
            'emotional_stability': stability,
            'arousal_valence_profile': arousal_valence,
            'prosody_consistency': prosody_consistency,
            'therapeutic_priority': self._compute_priority_score(),
            'intervention_suggestions': interventions
        }
```

---

## 5. Verbesserungspotenzial f√ºr Emotionserkennung

### 5.1 Precision-Recall-Analyse

**Aktuelle Limitationen:**
- Regel-basierte Klassifikation ohne Feedback-Mechanismus
- Fehlende Validierung gegen Ground Truth
- Keine Anpassung an individuelle Sprecher

### 5.2 Empfohlene Verbesserungen

1. **Multi-Feature Integration:**
   ```python
   # Erweiterte Feature-Set
   extended_features = {
       'acoustic': ['f0', 'rms', 'zcr', 'spectral_centroid', 'mfcc'],
       'prosodic': ['pause_patterns', 'speech_rate', 'rhythm'],
       'voice_quality': ['jitter', 'shimmer', 'hnr'],
       'temporal': ['f0_delta', 'energy_delta', 'stability_measures']
   }
   ```

2. **Machine Learning Integration:**
   ```python
   class MLEnhancedEmotionClassifier:
       def __init__(self):
           self.models = {
               'svm_classifier': None,  # F√ºr robuste Klassifikation
               'neural_network': None,  # F√ºr komplexe Muster
               'ensemble_method': None  # Kombination mehrerer Ans√§tze
           }
       
       def train_adaptive_model(self, training_data):
           # Online-Learning f√ºr kontinuierliche Verbesserung
           pass
   ```

3. **Confidence-basierte Ausgabe:**
   ```python
   def enhanced_emotion_output(self, features):
       predictions = {}
       for emotion in self.emotion_classes:
           confidence = self._compute_emotion_confidence(emotion, features)
           predictions[emotion] = confidence
       
       # Top-K Emotionen mit Konfidenz
       top_emotions = sorted(predictions.items(), 
                           key=lambda x: x[1], reverse=True)[:3]
       
       return {
           'primary_emotion': top_emotions[0][0],
           'confidence': top_emotions[0][1],
           'alternative_emotions': top_emotions[1:],
           'ambiguity_score': self._compute_ambiguity(predictions)
       }
   ```

---

## 6. Implementierungs-Roadmap

### Phase 1: Foundation (Kurzfristig)
- [ ] Z-Score Normalisierung implementieren
- [ ] Moving Average Gl√§ttung hinzuf√ºgen
- [ ] Erweiterte Pause-Klassifikation
- [ ] Loudness Spike Detection

### Phase 2: Enhancement (Mittelfristig)
- [ ] Adaptive Gewichtung implementieren
- [ ] Machine Learning Integration
- [ ] Therapeutische Marker erweitern
- [ ] Konfidenz-basierte Ausgabe

### Phase 3: Optimization (Langfristig)
- [ ] Online-Learning Mechanismen
- [ ] Sprecher-adaptive Kalibrierung
- [ ] Real-time Performance Optimierung
- [ ] Klinische Validierung

---

## 7. Fazit und Empfehlungen

### St√§rken des aktuellen Systems:
- ‚úÖ Solide Grundlagen f√ºr Prosody-Analyse
- ‚úÖ Therapeutisch relevante Emotionskategorien
- ‚úÖ Echtzeit-Verarbeitung
- ‚úÖ WebRTC VAD f√ºr robuste Spracherkennung

### Kritische Verbesserungsbedarfe:
- üîß **Hohe Priorit√§t:** Z-Score Normalisierung und Moving Average
- üîß **Hohe Priorit√§t:** Adaptive Gewichtung statt statischer Schwellenwerte
- üîß **Mittlere Priorit√§t:** Loudness Spike Detection
- üîß **Mittlere Priorit√§t:** Erweiterte Pause-Klassifikation

### Erwartete Verbesserungen:
- **+25-40% Pr√§zision** bei Emotionserkennung durch statistische Normalisierung
- **+30% Robustheit** gegen Sprecher-Variabilit√§t
- **+20% Therapeutische Relevanz** durch erweiterte Marker-Analyse

### N√§chste Schritte:
1. Implementierung der Z-Score Normalisierung als erste Priorit√§t
2. Integration von Moving Average Gl√§ttung
3. Schrittweise Einf√ºhrung der adaptiven Gewichtung
4. Klinische Evaluierung der Verbesserungen

---

*Analysiert mit Claude Code Quality Analyzer - Optimiert f√ºr therapeutische Anwendungen*